{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证策略\n",
    "\n",
    "[Scikit-learn validator](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "\n",
    "[Cross-validation for time series](https://robjhyndman.com/hyndsight/tscv/)\n",
    "\n",
    "[Ordered cross-validation](https://github.com/MaxHalford/xam/blob/master/docs/model-selection.md#ordered-cross-validation)\n",
    "\n",
    "[Cross-Validation Methodology Using '16 Golden Week](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/45266)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('./data/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('./data/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('./data/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('./data/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('./data/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('./data/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('./data/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('./data/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "# 初始处理:\n",
    "#       1. 从tes数据id中提取air_store_id和visit_datetime\n",
    "#       2. 在HPG预订信息中匹配air_store_id\n",
    "#       2. 转换visit_datetime和reserve_datetime为时间格式\n",
    "print(\"Init.\")\n",
    "# 1.\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "# 2.\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "# 3.\n",
    "for k in data:\n",
    "    if 'visit_date' in data[k].columns:\n",
    "        data[k]['visit_date'] = pd.to_datetime(data[k]['visit_date'])\n",
    "    if 'visit_datetime' in data[k].columns:\n",
    "        data[k]['visit_date'] = pd.to_datetime(data[k]['visit_datetime'].str.split().str[0])\n",
    "        data[k].drop('visit_datetime', axis=1, inplace=True)\n",
    "    if 'reserve_datetime' in data[k].columns:\n",
    "        data[k]['reserve_date'] = pd.to_datetime(data[k]['reserve_datetime'].str.split().str[0])\n",
    "        data[k].drop('reserve_datetime', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义特征抽取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count / ratio\n",
    "# data['tra'].groupby('air_store_id')['visitors'].sum()\n",
    "def time_feats(df, dt_col='visit_date'):\n",
    "    df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    df.loc[:, 'year'] = df[dt_col].dt.year\n",
    "    df.loc[:, 'dow'] = df[dt_col].dt.dayofweek\n",
    "    df.loc[:, 'month'] = df[dt_col].dt.month\n",
    "    df.loc[:, 'season'] = df[dt_col].dt.quarter\n",
    "    df.loc[:, 'week'] = df[dt_col].dt.weekofyear\n",
    "    df.loc[:, 'doy'] = df[dt_col].dt.dayofyear\n",
    "    df.loc[:, 'date_int'] = df[dt_col].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "\n",
    "# 增加时间特征\n",
    "time_feats(data['tra'])\n",
    "time_feats(data['tes'])\n",
    "\n",
    "# 匹配genre和area信息\n",
    "data['tra'] = data['tra'].merge(data['as'][['air_store_id', 'air_genre_name', 'air_area_name']], how='left', on='air_store_id')\n",
    "data['tes'] = data['tes'].merge(data['as'][['air_store_id', 'air_genre_name', 'air_area_name']], how='left', on='air_store_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PART1. Count & Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store\n",
    "# 1. overall\n",
    "store_agg_all = data['tra'].groupby('air_store_id')['visitors'].agg([np.sum, np.mean, np.std])\n",
    "\n",
    "# 2. monthly data\n",
    "store_cnt_monthly = data['tra'].groupby(['air_store_id', 'year', 'month'])['visitors'].sum().to_frame().reset_index()  # 过程数据\n",
    "store_mean_std_monthly = store_cnt_monthly.groupby('air_store_id')['visitors'].agg([np.mean, np.std])\n",
    "store_agg_monthly = store_cnt_monthly.groupby(['air_store_id', 'month'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "store_agg_monthly.columns = ['min_m', 'mean_m', 'median_m', 'max_m']\n",
    "store_agg_monthly.loc[:, 'ratio_m'] = store_agg_monthly['mean_m'] / store_mean_std_monthly['mean']\n",
    "\n",
    "# 3. weekly data\n",
    "store_cnt_weekly = data['tra'].groupby(['air_store_id', 'year', 'month', 'week'])['visitors'].sum().to_frame().reset_index()  # 过程数据\n",
    "store_mean_std_weekly = store_cnt_weekly.groupby('air_store_id')['visitors'].agg([np.mean, np.std])\n",
    "store_agg_weekly = store_cnt_weekly.groupby(['air_store_id', 'week'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "store_agg_weekly.columns = ['min_w', 'mean_w', 'median_w', 'max_w']\n",
    "store_agg_weekly.loc[:, 'ratio_w'] = store_agg_weekly['mean_w'] / store_mean_std_weekly['mean']\n",
    "\n",
    "# 4. dow data\n",
    "store_agg_dow = data['tra'].groupby(['air_store_id', 'dow'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max, np.std, np.size])\n",
    "store_agg_dow.columns = ['min_d', 'mean_d', 'median_d', 'max_d', 'std_d', 'len_d']\n",
    "store_agg_dow.loc[:, 'ratio_d'] = store_agg_dow['mean_d'] / store_agg_all['mean']\n",
    "\n",
    "# 5. penetration\n",
    "store_penetration = (data['tra'].groupby('air_store_id')['visitors'].sum() / data['tra']['visitors'].sum()).to_frame('penet_store')\n",
    "\n",
    "comment = '''\n",
    "store_agg_all                    --> <index> air_store_id,            <cols> sum, mean, std\n",
    "store_mean_std_monthly --> <index> air_store_id             <cols> mean, std\n",
    "store_agg_monthly          --> <index> air_store_id, month <cols> min_m, mean_m, median_m, max_m, ratio_m\n",
    "store_mean_std_weekly   --> <index> air_store_id,             <cols> mean, std\n",
    "store_agg_weekly            --> <index> air_store_id, week    <cols> min_w, mean_w, median_w, max_w, ratio_w\n",
    "store_agg_dow                --> <index> air_store_id, dow      <cols> min_d, mean_d, median_d, max_d, std_d, len_d, ratio_d\n",
    "store_penetration            --> <index> air_store_id               <cols> penet_store\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Genre\n",
    "# 1. overall\n",
    "genre_agg_all = data['tra'].groupby('air_genre_name')['visitors'].agg([np.sum, np.mean, np.std])\n",
    "\n",
    "# 2. monthly data\n",
    "genre_cnt_monthly = data['tra'].groupby(['air_genre_name', 'year', 'month'])['visitors'].sum().to_frame().reset_index()\n",
    "genre_mean_std_monthly = genre_cnt_monthly.groupby('air_genre_name')['visitors'].agg([np.mean, np.std])\n",
    "genre_agg_monthly = genre_cnt_monthly.groupby(['air_genre_name', 'month'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "genre_agg_monthly.columns = ['min_m', 'mean_m', 'median_m', 'max_m']\n",
    "genre_agg_monthly.loc[:, 'ratio_m'] = genre_agg_monthly['mean_m'] / genre_mean_std_monthly['mean']\n",
    "\n",
    "# 3. weekly data\n",
    "genre_cnt_weekly = data['tra'].groupby(['air_genre_name', 'year', 'month', 'week'])['visitors'].sum().to_frame().reset_index()\n",
    "genre_mean_std_weekly = genre_cnt_weekly.groupby('air_genre_name')['visitors'].agg([np.mean, np.std])\n",
    "genre_agg_weekly = genre_cnt_weekly.groupby(['air_genre_name', 'week'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "genre_agg_weekly.columns = ['min_w', 'mean_w', 'median_w', 'max_w']\n",
    "genre_agg_weekly.loc[:, 'ratio_w'] = genre_agg_weekly['mean_w'] / genre_mean_std_weekly['mean']\n",
    "\n",
    "# 4. dow data\n",
    "genre_agg_dow = data['tra'].groupby(['air_genre_name', 'dow'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max, np.std, np.size])\n",
    "genre_agg_dow.columns = ['min_d', 'mean_d', 'median_d', 'max_d', 'std_d', 'len_d']\n",
    "genre_agg_dow.loc[:, 'ratio_d'] = genre_agg_dow['mean_d'] / genre_agg_all['mean']\n",
    "\n",
    "# 5. penetration\n",
    "genre_penetration = (data['tra'].groupby('air_genre_name')['visitors'].sum() / data['tra']['visitors'].sum()).to_frame('penet_genre')\n",
    "\n",
    "comment = '''\n",
    "genre_agg_all                    --> <index> air_genre_name,              <cols> sum, mean, std\n",
    "genre_mean_std_monthly --> <index> air_genre_name               <cols> mean, std\n",
    "genre_agg_monthly          --> <index> air_genre_name, month   <cols> min_m, mean_m, median_m, max_m, ratio_m\n",
    "genre_mean_std_weekly   --> <index> air_genre_name,               <cols> mean, std\n",
    "genre_agg_weekly            --> <index> air_genre_name, week      <cols> min_w, mean_w, median_w, max_w, ratio_w\n",
    "genre_agg_dow                --> <index> air_genre_name, dow       <cols> min_d, mean_d, median_d, max_d, std_d, len_d, ratio_d\n",
    "genre_penetration            --> <index> air_genre_name                <cols> penet_genre\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Area\n",
    "# 1. overall\n",
    "area_agg_all = data['tra'].groupby('air_area_name')['visitors'].agg([np.sum, np.mean, np.std])\n",
    "\n",
    "# 2. monthly data\n",
    "area_cnt_monthly = data['tra'].groupby(['air_area_name', 'year', 'month'])['visitors'].sum().to_frame().reset_index()\n",
    "area_mean_std_monthly = area_cnt_monthly.groupby('air_area_name')['visitors'].agg([np.mean, np.std])\n",
    "area_agg_monthly = area_cnt_monthly.groupby(['air_area_name', 'month'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "area_agg_monthly.columns = ['min_m', 'mean_m', 'median_m', 'max_m']\n",
    "area_agg_monthly.loc[:, 'ratio_m'] = area_agg_monthly['mean_m'] / area_mean_std_monthly['mean']\n",
    "\n",
    "# 3. weekly data\n",
    "area_cnt_weekly = data['tra'].groupby(['air_area_name', 'year', 'month', 'week'])['visitors'].sum().to_frame().reset_index()\n",
    "area_mean_std_weekly = area_cnt_weekly.groupby('air_area_name')['visitors'].agg([np.mean, np.std])\n",
    "area_agg_weekly = area_cnt_weekly.groupby(['air_area_name', 'week'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "area_agg_weekly.columns = ['min_w', 'mean_w', 'median_w', 'max_w']\n",
    "area_agg_weekly.loc[:, 'ratio_w'] = area_agg_weekly['mean_w'] / area_mean_std_weekly['mean']\n",
    "\n",
    "# 4. dow data\n",
    "area_agg_dow = data['tra'].groupby(['air_area_name', 'dow'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max, np.std, np.size])\n",
    "area_agg_dow.columns = ['min_d', 'mean_d', 'median_d', 'max_d', 'std_d', 'len_d']\n",
    "area_agg_dow.loc[:, 'ratio_d'] = area_agg_dow['mean_d'] / area_agg_all['mean']\n",
    "\n",
    "# 5. penetration\n",
    "area_penetration = (data['tra'].groupby('air_area_name')['visitors'].sum() / data['tra']['visitors'].sum()).to_frame('penet_area')\n",
    "\n",
    "comment = '''\n",
    "area_agg_all                    --> <index> air_area_name,              <cols> sum, mean, std\n",
    "area_mean_std_monthly --> <index> air_area_name               <cols> mean, std\n",
    "area_agg_monthly          --> <index> air_area_name, month   <cols> min_m, mean_m, median_m, max_m, ratio_m\n",
    "area_mean_std_weekly   --> <index> air_area_name,               <cols> mean, std\n",
    "area_agg_weekly            --> <index> air_area_name, week      <cols> min_w, mean_w, median_w, max_w, ratio_w\n",
    "area_agg_dow                --> <index> air_area_name, dow       <cols> min_d, mean_d, median_d, max_d, std_d, len_d, ratio_d\n",
    "area_penetration            --> <index> air_area_name                <cols> penet_area\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genre X area\n",
    "# data['tra']['air_area_name1'] = data['tra']['air_area_name'].apply(lambda x: x.split()[0].split('-')[0])\n",
    "# data['tra']['air_area_name2'] = data['tra']['air_area_name'].apply(lambda x: ' '.join(x.split()[:2]))\n",
    "\n",
    "# 1. overall count\n",
    "genre_area_cnt_all = data['tra'].groupby(['air_genre_name', 'air_area_name'])['visitors'].agg([np.sum, np.mean, np.std])\n",
    "\n",
    "# 2. monthly data\n",
    "genre_area_cnt_monthly = data['tra'].groupby(['air_genre_name', 'air_area_name', 'year', 'month'])['visitors'].sum().to_frame().reset_index()\n",
    "genre_area_mean_std_monthly = genre_area_cnt_monthly.groupby(['air_genre_name', 'air_area_name'])['visitors'].agg([np.mean, np.std])\n",
    "genre_area_agg_monthly = genre_area_cnt_monthly.groupby(['air_genre_name', 'air_area_name', 'month'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "genre_area_agg_monthly.columns = ['min_m', 'mean_m', 'median_m', 'max_m']\n",
    "\n",
    "# genre_area_agg_monthly.loc['ratio_m'] = genre_area_agg_monthly['mean_m'] / genre_area_mean_std_monthly['mean'] # 比率属性: 报错了\n",
    "\n",
    "# 3. weekly data\n",
    "genre_area_cnt_weekly = data['tra'].groupby(['air_genre_name', 'air_area_name', 'year', 'month', 'week'])['visitors'].sum().to_frame().reset_index()\n",
    "genre_area_mean_std_weekly = genre_area_cnt_weekly.groupby(['air_genre_name', 'air_area_name'])['visitors'].agg([np.mean, np.std])\n",
    "genre_area_agg_weekly = genre_area_cnt_weekly.groupby(['air_genre_name', 'air_area_name', 'week'])['visitors'].agg(\n",
    "    [np.min, np.mean, np.median, np.max])\n",
    "genre_area_agg_weekly.columns = ['min_w', 'mean_w', 'median_w', 'max_w']\n",
    "\n",
    "# 4. dow data\n",
    "genre_area_agg_dow = data['tra'].groupby(['air_genre_name', 'air_area_name', 'dow'])['visitors'].agg(\n",
    "                                      [np.min, np.mean, np.median, np.max, np.std, np.size])\n",
    "genre_area_agg_dow.columns = ['min_d', 'mean_d', 'median_d', 'max_d', 'std_d', 'len_d']\n",
    "# genre_area_agg_dow.loc[:, 'ratio_d'] = genre_area_agg_dow['mean_d'] / genre_area_cnt_all['mean']\n",
    "# NotImplementedError: merging with more than one level overlap on a multi-index is not implemented\n",
    "\n",
    "# 5. penetration\n",
    "genre_area_penetration = (data['tra'].groupby(['air_genre_name', 'air_area_name'])['visitors'].sum() / data['tra']['visitors'].sum()).to_frame('penet_ga')\n",
    "\n",
    "# WARNING: 多样性信息可以加上HPG系统的store信息，可以两边都用\n",
    "# 6. diversity\n",
    "genre_area_diver = data['tra'][['air_store_id', 'air_genre_name', 'air_area_name']].groupby([\n",
    "    'air_genre_name', 'air_area_name'])['air_store_id'].nunique().to_frame('store_num').reset_index()\n",
    "genre_num = data['tra'].groupby('air_genre_name')['air_store_id'].nunique()\n",
    "area_num = data['tra'].groupby('air_area_name')['air_store_id'].nunique()\n",
    "\n",
    "genre_area_diver = genre_area_diver.merge(area_num.to_frame(name='area_store_num'), how='left', left_on='air_area_name', right_index=True)\n",
    "genre_area_diver = genre_area_diver.merge(genre_num.to_frame(name='genre_store_num'), how='left', left_on='air_genre_name', right_index=True)\n",
    "genre_area_diver.loc[:, 'area_store_ratio'] = genre_area_diver['store_num'] / genre_area_diver['area_store_num']\n",
    "genre_area_diver.loc[:, 'genre_store_ratio'] = genre_area_diver['store_num'] / genre_area_diver['genre_store_num']\n",
    "genre_area_diver.set_index(['air_genre_name', 'air_area_name'], inplace=True)\n",
    "\n",
    "comment = '''\n",
    "genre_area_cnt_all                     --> <index> air_genre_name, air_area_name                <cols> sum, mean, std\n",
    "genre_area_mean_std_monthly --> <index> air_genre_name, air_area_name                <cols> mean, std\n",
    "genre_area_agg_monthly          --> <index> air_genre_name, air_area_name, month    <cols> min_m, mean_m, median_m, max_m\n",
    "genre_area_mean_std_weekly   --> <index> air_genre_name, air_area_name,               <cols> mean, std\n",
    "genre_area_agg_weekly            --> <index> air_genre_name, air_area_name, week      <cols> min_w, mean_w, median_w, max_w\n",
    "genre_area_agg_dow                --> <index> air_genre_name, air_area_name, dow        <cols> min_d, mean_d, median_d, max_d, std_d, len_d\n",
    "genre_area_penetration            --> <index> air_genre_name, air_area_name,                <cols> penet_ga\n",
    "genre_area_diver                       --> <index> air_genre_name, air_area_name,                <cols> store_num, area_store_num, genre_store_num\n",
    "                                                                                                                                                       area_store_ratio, genre_store_ratio\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>store_num</th>\n",
       "      <th>area_store_num</th>\n",
       "      <th>genre_store_num</th>\n",
       "      <th>area_store_ratio</th>\n",
       "      <th>genre_store_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <th>Tōkyō-to Shibuya-ku Shibuya</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Bar/Cocktail</th>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Daimyō</th>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.088608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Hakata Ekimae</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.025316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hiroshima-ken Hiroshima-shi Kokutaijimachi</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>79</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.025316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hokkaidō Asahikawa-shi 6 Jōdōri</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.050633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           store_num  \\\n",
       "air_genre_name air_area_name                                           \n",
       "Asian          Tōkyō-to Shibuya-ku Shibuya                         2   \n",
       "Bar/Cocktail   Fukuoka-ken Fukuoka-shi Daimyō                      7   \n",
       "               Fukuoka-ken Fukuoka-shi Hakata Ekimae               2   \n",
       "               Hiroshima-ken Hiroshima-shi Kokutaijimachi          2   \n",
       "               Hokkaidō Asahikawa-shi 6 Jōdōri                     4   \n",
       "\n",
       "                                                           area_store_num  \\\n",
       "air_genre_name air_area_name                                                \n",
       "Asian          Tōkyō-to Shibuya-ku Shibuya                             58   \n",
       "Bar/Cocktail   Fukuoka-ken Fukuoka-shi Daimyō                          64   \n",
       "               Fukuoka-ken Fukuoka-shi Hakata Ekimae                   16   \n",
       "               Hiroshima-ken Hiroshima-shi Kokutaijimachi              23   \n",
       "               Hokkaidō Asahikawa-shi 6 Jōdōri                         13   \n",
       "\n",
       "                                                           genre_store_num  \\\n",
       "air_genre_name air_area_name                                                 \n",
       "Asian          Tōkyō-to Shibuya-ku Shibuya                               2   \n",
       "Bar/Cocktail   Fukuoka-ken Fukuoka-shi Daimyō                           79   \n",
       "               Fukuoka-ken Fukuoka-shi Hakata Ekimae                    79   \n",
       "               Hiroshima-ken Hiroshima-shi Kokutaijimachi               79   \n",
       "               Hokkaidō Asahikawa-shi 6 Jōdōri                          79   \n",
       "\n",
       "                                                           area_store_ratio  \\\n",
       "air_genre_name air_area_name                                                  \n",
       "Asian          Tōkyō-to Shibuya-ku Shibuya                         0.034483   \n",
       "Bar/Cocktail   Fukuoka-ken Fukuoka-shi Daimyō                      0.109375   \n",
       "               Fukuoka-ken Fukuoka-shi Hakata Ekimae               0.125000   \n",
       "               Hiroshima-ken Hiroshima-shi Kokutaijimachi          0.086957   \n",
       "               Hokkaidō Asahikawa-shi 6 Jōdōri                     0.307692   \n",
       "\n",
       "                                                           genre_store_ratio  \n",
       "air_genre_name air_area_name                                                  \n",
       "Asian          Tōkyō-to Shibuya-ku Shibuya                          1.000000  \n",
       "Bar/Cocktail   Fukuoka-ken Fukuoka-shi Daimyō                       0.088608  \n",
       "               Fukuoka-ken Fukuoka-shi Hakata Ekimae                0.025316  \n",
       "               Hiroshima-ken Hiroshima-shi Kokutaijimachi           0.025316  \n",
       "               Hokkaidō Asahikawa-shi 6 Jōdōri                      0.050633  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_area_diver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "#   1. 重命名\n",
    "#   2. 匹配对应值\n",
    "#   3. fillna\n",
    "\n",
    "for df, cols in (\n",
    "                    (store_agg_all,  ['sum_s', 'mean_s', 'std_s']),\n",
    "                    (store_mean_std_monthly, ['mean_s_mon', 'std_s_mon']),\n",
    "                    (store_agg_monthly, ['min_s_m', 'mean_s_m', 'median_s_m', 'max_s_m', 'ratio_s_m']),\n",
    "                    (store_mean_std_weekly, ['mean_s_week', 'std_s_week']),\n",
    "                    (store_agg_weekly, ['min_s_w', 'mean_s_w', 'median_s_w', 'max_s_w', 'ratio_s_w']),\n",
    "                    (store_agg_dow, ['min_s_d', 'mean_s_d', 'median_s_d', 'max_s_d', 'std_s_d', 'len_s_d', 'ratio_s_d']),\n",
    "                    (store_penetration, ['penet_store',]),\n",
    "                    (genre_agg_all, ['sum_g', 'mean_g', 'std_g']),\n",
    "                    (genre_mean_std_monthly, ['mean_g_mon', 'std_g_mon']),\n",
    "                    (genre_agg_monthly, ['min_g_m', 'mean_g_m', 'median_g_m', 'max_g_m', 'ratio_g_m']),\n",
    "                    (genre_mean_std_weekly, ['mean_g_week', 'std_g_week']),\n",
    "                    (genre_agg_weekly, ['min_g_w', 'mean_g_w', 'median_g_w', 'max_g_w', 'ratio_g_w']),\n",
    "                    (genre_agg_dow, ['min_g_d', 'mean_g_d', 'median_g_d', 'max_g_d', 'std_g_d', 'len_g_d', 'ratio_g_d']),\n",
    "                    (genre_penetration, ['penet_genre',]),\n",
    "                    (area_agg_all, ['sum_a', 'mean_a', 'std_a']),\n",
    "                    (area_mean_std_monthly, ['mean_a_mon', 'std_a_mon']),\n",
    "                    (area_agg_monthly, ['min_a_m', 'mean_a_m', 'median_a_m', 'max_a_m', 'ratio_a_m']),\n",
    "                    (area_mean_std_weekly, ['mean_a_week', 'std_a_week']),\n",
    "                    (area_agg_weekly, ['min_a_w', 'mean_a_w', 'median_a_w', 'max_a_w', 'ratio_a_w']),\n",
    "                    (area_agg_dow, ['min_a_d', 'mean_a_d', 'median_a_d', 'max_a_d', 'std_a_d', 'len_a_d', 'ratio_a_d']),\n",
    "                    (area_penetration, ['penet_area', ]),\n",
    "                    (genre_area_cnt_all, ['sum_ga', 'mean_ga', 'std_ga']),\n",
    "                    (genre_area_mean_std_monthly, ['mean_ga_mon', 'std_ga_mon']),\n",
    "                    (genre_area_agg_monthly, ['min_ga_m', 'mean_ga_m', 'median_ga_m', 'max_ga_m']),\n",
    "                    (genre_area_mean_std_weekly, ['mean_ga_week', 'std_ga_week']),\n",
    "                    (genre_area_agg_weekly, ['min_ga_w', 'mean_ga_w', 'median_ga_w', 'max_ga_w']),\n",
    "                    (genre_area_agg_dow, ['min_ga_d', 'mean_ga_d', 'median_ga_d', 'max_ga_d', 'std_ga_d', 'len_ga_d']),\n",
    "                    (genre_area_penetration, ['penet_ga',]),\n",
    "                    (genre_area_diver, ['store_num', 'area_store_num', 'genre_store_num', 'area_store_ratio', 'genre_store_ratio'])\n",
    "                ):\n",
    "    df.columns = cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART2. 时间 & Genre & Area & Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# part2\n",
    "# 为df加上时间标记: dow, month, year, date\n",
    "def time_feats(df, dt_col='visit_date'):\n",
    "    df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    df.loc[:, 'year'] = df[dt_col].dt.year\n",
    "    df.loc[:, 'dow'] = df[dt_col].dt.dayofweek\n",
    "    df.loc[:, 'month'] = df[dt_col].dt.month\n",
    "    df.loc[:, 'season'] = df[dt_col].dt.quarter\n",
    "    df.loc[:, 'week'] = df[dt_col].dt.weekofyear\n",
    "    df.loc[:, 'doy'] = df[dt_col].dt.dayofyear\n",
    "    df.loc[:, 'date_int'] = df[dt_col].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "    return df\n",
    "\n",
    "# 预订数据特征\n",
    "# WARNING: 测试数据中没有reserve数据, 只有reserve_visit数据 \n",
    "def order_feats(order_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `visit_date`, ...\n",
    "    '''\n",
    "    order = order_data.copy()\n",
    "    # 创建新特征datetime_diff: 表示到店时间和预订时间的差值\n",
    "    order['reserve_date_diff'] = order.apply(\n",
    "        lambda r: (r['visit_date'] - r['reserve_date']).days,\n",
    "        axis=1)\n",
    "\n",
    "    # 以(air_store_id, visit_date)为分组计算预订时间差和预订人数的总和(sum: tmp1)与均值(mean: tmp2)\n",
    "    tmp1 = order.groupby(['air_store_id','visit_date'],\n",
    "        as_index=False)[['reserve_date_diff', 'reserve_visitors']].sum().rename(\n",
    "        columns={'visit_date':'visit_date', 'reserve_date_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = order.groupby(['air_store_id','visit_date'],\n",
    "        as_index=False)[['reserve_date_diff', 'reserve_visitors']].mean().rename(\n",
    "        columns={'visit_date':'visit_date', 'reserve_date_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    order = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "    return order\n",
    "\n",
    "\n",
    "# 以(air_store_id, dow)为分组，计算visitors的最小值，均值，中位数，最大值，样本大小\n",
    "# 主要计算了时间（dow）相关的信息\n",
    "def store_x_dow(tra, tes):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `dow`, ...\n",
    "    '''\n",
    "    unique_stores = tes['air_store_id'].unique()\n",
    "    stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores,\n",
    "                                      'dow': [i]*len(unique_stores)}) for i in range(7)],\n",
    "                        axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    tmp = tra.groupby(['air_store_id','dow']).agg(\n",
    "        {'visitors': [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n",
    "    tmp.columns = ['air_store_id', 'dow', 'min_visitors', 'mean_visitors',\n",
    "                   'median_visitors','max_visitors','count_observations']\n",
    "    stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "    return stores\n",
    "\n",
    "\n",
    "def genre_feats(store_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, ...\n",
    "    '''\n",
    "    store_info = store_data[['air_store_id', 'air_genre_name']].copy()\n",
    "    \n",
    "    '''\n",
    "    store_info['air_genre_name'] = store_info['air_genre_name'].map(\n",
    "        lambda x: str(str(x).replace('/',' ')))\n",
    "    lbl = LabelEncoder()\n",
    "    max_genre = np.max((store_info['air_genre_name'].str.split().apply(lambda x: len(x))))\n",
    "    for i in range(max_genre):\n",
    "        store_info['air_genre_name'+str(i)] = lbl.fit_transform(store_info['air_genre_name'].map(\n",
    "            lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    # store_info['air_genre_name'] = lbl.fit_transform(store_info['air_genre_name'])  # 对genre_name进行直接编码\n",
    "    '''\n",
    "\n",
    "    store_info = pd.concat([store_info, pd.get_dummies(store_info['air_genre_name'])], axis=1)\n",
    "    \n",
    "    return store_info\n",
    "\n",
    "\n",
    "def area_feats(store_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, ...\n",
    "    '''\n",
    "    store_info = store_data[['air_store_id', 'air_area_name', 'latitude', 'longitude']].copy()\n",
    "    # 区域名称特征\n",
    "    # store_info['air_area_name'] = store_info['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))  # 把'-' 换成空格' '\n",
    "    store_info['air_area_alias'] = store_info['air_area_name'].map(lambda x: re.sub('(-\\w+?|\\d)', '', x))  # 把\"-xxx\"或者数字换成空字符串\n",
    "\n",
    "    '''\n",
    "    lbl = LabelEncoder()\n",
    "    max_area = np.max((store_info['air_area_name'].str.split().apply(lambda x: len(x))))\n",
    "    for i in range(max_area):\n",
    "        store_info['air_area_name'+str(i)] = lbl.fit_transform(store_info['air_area_alias'].map(\n",
    "            lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    # store_info['air_area_name'] = lbl.fit_transform(store_info['air_area_name'])  # 对area_name进行直接编码\n",
    "    store_info.drop('air_area_alias', axis=1, inplace=True)\n",
    "    '''\n",
    "    \n",
    "    # 区域坐标特征\n",
    "    # 经纬度特征\n",
    "    store_info['var_max_lat'] = store_info['latitude'].max() - store_info['latitude']\n",
    "    store_info['var_max_long'] = store_info['longitude'].max() - store_info['longitude']\n",
    "    # NEW FEATURES FROM Georgii Vyshnia\n",
    "    # 经度 + 纬度?\n",
    "    store_info['lon_plus_lat'] = store_info['longitude'] + store_info['latitude']\n",
    "    \n",
    "    store_info = pd.concat([\n",
    "        store_info.drop('air_area_alias', axis=1),\n",
    "        pd.get_dummies(store_info['air_area_alias'].str.split().str[0])\n",
    "    ], axis=1)\n",
    "\n",
    "    return store_info\n",
    "\n",
    "\n",
    "def holiday_feats(holiday):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `visit_date`, ...\n",
    "    '''\n",
    "    tmp = holiday.drop('day_of_week', axis=1)\n",
    "    # 周末的holiday_flg置为0\n",
    "    tmp.loc[(tmp['visit_date'].dt.dayofweek>4) & tmp['holiday_flg']==1, :] = 0\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def mean_avg(tra, hol):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `dow`, `holiday_flg`, `visitors_mv`\n",
    "    '''\n",
    "    air_visit_data = tra.copy()\n",
    "    date_info = hol.copy()\n",
    "    # 把周末的holiday_flag置为0\n",
    "    date_info.loc[(date_info['visit_date'].dt.dayofweek>4) & date_info['holiday_flg']==1, :] = 0\n",
    "\n",
    "    # 根据hol.index计算日期对应的权重weight\n",
    "    date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5\n",
    "\n",
    "    # 在visit_data中匹配日期weight\n",
    "    visit_data = air_visit_data.merge(date_info, on='visit_date', how='left')\n",
    "\n",
    "    # 将访问量转化为对数访问量log1p\n",
    "    visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "    # 按照 air_store_id, dow, holiday_flg 的分组计算加权平均\n",
    "    visitors = visit_data.groupby(['air_store_id', 'dow', 'holiday_flg']).apply(\n",
    "        lambda x:( (x['weight'] * x['visitors']).sum() / x['weight'].sum() )).reset_index()\n",
    "    visitors.rename(columns={0:'visitors_mv'}, inplace=True) \n",
    "    return visitors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>doy</th>\n",
       "      <th>date_int</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20160113</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20160114</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>20160115</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20160116</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>20160118</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors  year  dow  month  season  week  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13        25  2016    2      1       1     2   \n",
       "1  air_ba937bf13d40fb24 2016-01-14        32  2016    3      1       1     2   \n",
       "2  air_ba937bf13d40fb24 2016-01-15        29  2016    4      1       1     2   \n",
       "3  air_ba937bf13d40fb24 2016-01-16        22  2016    5      1       1     2   \n",
       "4  air_ba937bf13d40fb24 2016-01-18         6  2016    0      1       1     3   \n",
       "\n",
       "   doy  date_int air_genre_name                 air_area_name  \n",
       "0   13  20160113     Dining bar  Tōkyō-to Minato-ku Shibakōen  \n",
       "1   14  20160114     Dining bar  Tōkyō-to Minato-ku Shibakōen  \n",
       "2   15  20160115     Dining bar  Tōkyō-to Minato-ku Shibakōen  \n",
       "3   16  20160116     Dining bar  Tōkyō-to Minato-ku Shibakōen  \n",
       "4   18  20160118     Dining bar  Tōkyō-to Minato-ku Shibakōen  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tra'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set features.\n",
      "Processing Order data...\n",
      "Processing Store X dow...\n",
      "Processing Genre_feats...\n",
      "Processing Area_feats...\n",
      "Processing Holiday_feats...\n",
      "Test set features.\n",
      "Processing Order data...\n",
      "Processing Store X dow...\n",
      "Processing Genre_feats...\n",
      "Processing Area_feats...\n",
      "Processing Holiday_feats...\n",
      "Processing Total_order_feats...\n",
      "Processing lat&lon_feats...\n"
     ]
    }
   ],
   "source": [
    "# 增加时间特征\n",
    "# train = time_feats(data['tra'])\n",
    "# test = time_feats(data['tes'])\n",
    "\n",
    "train = data['tra'].drop(['air_genre_name', 'air_area_name'], axis=1).copy()\n",
    "test = data['tes'].drop(['air_genre_name', 'air_area_name'], axis=1).copy()\n",
    "\n",
    "'''\n",
    "for df in [train, test]:\n",
    "    print(\"Processing Order data...\")\n",
    "    df = pd.merge(df, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "    df = pd.merge(df, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "    print(\"Processing Store X dow...\")\n",
    "    df = pd.merge(df, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "    print(\"Processing Genre_feats...\")\n",
    "    df = pd.merge(df, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "    print(\"Processing Area_feats...\")\n",
    "    df = pd.merge(df, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "    print(\"Processing Holiday_feats...\")\n",
    "    df = pd.merge(df, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "    df.fillna(-1)\n",
    "'''\n",
    "\n",
    "print(\"Train set features.\")\n",
    "print(\"Processing Order data...\")\n",
    "train = pd.merge(train, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "train = pd.merge(train, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "print(\"Processing Store X dow...\")\n",
    "train = pd.merge(train, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "print(\"Processing Genre_feats...\")\n",
    "train = pd.merge(train, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Area_feats...\")\n",
    "train = pd.merge(train, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Holiday_feats...\")\n",
    "train = pd.merge(train, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "train.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Test set features.\")\n",
    "print(\"Processing Order data...\")\n",
    "test = pd.merge(test, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "test = pd.merge(test, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "print(\"Processing Store X dow...\")\n",
    "test = pd.merge(test, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "print(\"Processing Genre_feats...\")\n",
    "test = pd.merge(test, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Area_feats...\")\n",
    "test = pd.merge(test, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Holiday_feats...\")\n",
    "test = pd.merge(test, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "# 增加预订总和以及预订平均值特征\n",
    "print(\"Processing Total_order_feats...\")\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "# 经纬度特征\n",
    "print(\"Processing lat&lon_feats...\")\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "# 经度 + 纬度?\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude']\n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_a</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>std_a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_area_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Daimyō</th>\n",
       "      <td>408708</td>\n",
       "      <td>20.667914</td>\n",
       "      <td>16.846033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Hakata Ekimae</th>\n",
       "      <td>106994</td>\n",
       "      <td>21.149239</td>\n",
       "      <td>14.904164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Imaizumi</th>\n",
       "      <td>7644</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>9.101297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Momochi</th>\n",
       "      <td>41036</td>\n",
       "      <td>20.365261</td>\n",
       "      <td>19.039513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fukuoka-ken Fukuoka-shi Shiobaru</th>\n",
       "      <td>37400</td>\n",
       "      <td>17.163837</td>\n",
       "      <td>15.372278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sum_a     mean_a      std_a\n",
       "air_area_name                                                      \n",
       "Fukuoka-ken Fukuoka-shi Daimyō         408708  20.667914  16.846033\n",
       "Fukuoka-ken Fukuoka-shi Hakata Ekimae  106994  21.149239  14.904164\n",
       "Fukuoka-ken Fukuoka-shi Imaizumi         7644  15.925000   9.101297\n",
       "Fukuoka-ken Fukuoka-shi Momochi         41036  20.365261  19.039513\n",
       "Fukuoka-ken Fukuoka-shi Shiobaru        37400  17.163837  15.372278"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_agg_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匹配Count & Agg特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "train = train.merge(\n",
    "  store_agg_all,          how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_mean_std_monthly, how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_agg_monthly,      how='left', left_on=['air_store_id', 'month'],           right_index=True).merge(\n",
    "  store_mean_std_weekly,  how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_agg_weekly,       how='left', left_on=['air_store_id', 'week'],            right_index=True).merge(\n",
    "  store_agg_dow,          how='left', left_on=['air_store_id', 'dow'],             right_index=True).merge(\n",
    "  store_penetration,      how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  genre_agg_all,          how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_mean_std_monthly, how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_agg_monthly,      how='left', left_on=['air_genre_name', 'month'],         right_index=True).merge(\n",
    "  genre_mean_std_weekly,  how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_agg_weekly,       how='left', left_on=['air_genre_name', 'week'],          right_index=True).merge(\n",
    "  genre_agg_dow,          how='left', left_on=['air_genre_name', 'dow'],           right_index=True).merge(\n",
    "  genre_penetration,      how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  area_agg_all,           how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_mean_std_monthly,  how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_agg_monthly,       how='left', left_on=['air_area_name', 'month'],          right_index=True).merge(\n",
    "  area_mean_std_weekly,   how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_agg_weekly,        how='left', left_on=['air_area_name', 'week'],           right_index=True).merge(\n",
    "  area_agg_dow,           how='left', left_on=['air_area_name', 'dow'],            right_index=True).merge(\n",
    "  area_penetration,       how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  genre_area_cnt_all,     how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_mean_std_monthly, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_agg_monthly, how='left', left_on=['air_genre_name', 'air_area_name', 'month'], right_index=True).merge(\n",
    "  genre_area_mean_std_weekly, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_agg_weekly, how='left', left_on=['air_genre_name', 'air_area_name', 'week'], right_index=True).merge(\n",
    "  genre_area_agg_dow, how='left', left_on=['air_genre_name', 'air_area_name', 'dow'], right_index=True).merge(\n",
    "  genre_area_penetration, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_diver, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True)\n",
    "\n",
    "# Test set\n",
    "test = test.merge(\n",
    "  store_agg_all,          how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_mean_std_monthly, how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_agg_monthly,      how='left', left_on=['air_store_id', 'month'],           right_index=True).merge(\n",
    "  store_mean_std_weekly,  how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  store_agg_weekly,       how='left', left_on=['air_store_id', 'week'],            right_index=True).merge(\n",
    "  store_agg_dow,          how='left', left_on=['air_store_id', 'dow'],             right_index=True).merge(\n",
    "  store_penetration,      how='left', left_on='air_store_id',                      right_index=True).merge(\n",
    "  genre_agg_all,          how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_mean_std_monthly, how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_agg_monthly,      how='left', left_on=['air_genre_name', 'month'],         right_index=True).merge(\n",
    "  genre_mean_std_weekly,  how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  genre_agg_weekly,       how='left', left_on=['air_genre_name', 'week'],          right_index=True).merge(\n",
    "  genre_agg_dow,          how='left', left_on=['air_genre_name', 'dow'],           right_index=True).merge(\n",
    "  genre_penetration,      how='left', left_on='air_genre_name',                    right_index=True).merge(\n",
    "  area_agg_all,           how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_mean_std_monthly,  how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_agg_monthly,       how='left', left_on=['air_area_name', 'month'],          right_index=True).merge(\n",
    "  area_mean_std_weekly,   how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  area_agg_weekly,        how='left', left_on=['air_area_name', 'week'],           right_index=True).merge(\n",
    "  area_agg_dow,           how='left', left_on=['air_area_name', 'dow'],            right_index=True).merge(\n",
    "  area_penetration,       how='left', left_on='air_area_name',                     right_index=True).merge(\n",
    "  genre_area_cnt_all,     how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_mean_std_monthly, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_agg_monthly, how='left', left_on=['air_genre_name', 'air_area_name', 'month'], right_index=True).merge(\n",
    "  genre_area_mean_std_weekly, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_agg_weekly, how='left', left_on=['air_genre_name', 'air_area_name', 'week'], right_index=True).merge(\n",
    "  genre_area_agg_dow, how='left', left_on=['air_genre_name', 'air_area_name', 'dow'], right_index=True).merge(\n",
    "  genre_area_penetration, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True).merge(\n",
    "  genre_area_diver, how='left', left_on=['air_genre_name', 'air_area_name'], right_index=True)\n",
    "\n",
    "\n",
    "# 处理缺失值\n",
    "for idx in train.dtypes.loc[train.isnull().any(axis=0)].index:\n",
    "    train.loc[:, idx].fillna(train[idx].mean(), inplace=True)\n",
    "\n",
    "for idx in test.dtypes.loc[test.isnull().any(axis=0)].index:\n",
    "    test.loc[:, idx].fillna(test[idx].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移动平均预测特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mean Average feats...\n",
      "\tProcessing Train set\n",
      "\tProcessing Test set\n"
     ]
    }
   ],
   "source": [
    "# 添加移动平均预测特征\n",
    "print(\"Processing Mean Average feats...\")\n",
    "visitors_mv = mean_avg(data['tra'], data['hol'])\n",
    "\n",
    "print(\"\\tProcessing Train set\")\n",
    "train = pd.merge(train, visitors_mv, how='left', on=['air_store_id', 'dow', 'holiday_flg'])\n",
    "miss_idx = train['visitors_mv'].isnull()\n",
    "train.loc[miss_idx, 'visitors_mv'] = train[miss_idx].merge(visitors_mv.loc[visitors_mv.holiday_flg==0, ['air_store_id', 'dow', 'visitors_mv']],\n",
    "                                                           on=('air_store_id', 'dow'), how='left')['visitors_mv_y'].values\n",
    "miss_idx = train['visitors_mv'].isnull()\n",
    "train.loc[miss_idx, 'visitors_mv'] = train[miss_idx].merge(visitors_mv[['air_store_id', 'visitors_mv']].groupby('air_store_id').mean().reset_index(),\n",
    "                                                           on='air_store_id', how='left')['visitors_mv_y'].values\n",
    "\n",
    "print(\"\\tProcessing Test set\")\n",
    "test = pd.merge(test, visitors_mv, how='left', on=['air_store_id', 'dow', 'holiday_flg'])\n",
    "miss_idx = test['visitors_mv'].isnull()\n",
    "test.loc[miss_idx, 'visitors_mv'] = test[miss_idx].merge(visitors_mv.loc[visitors_mv.holiday_flg==0, ['air_store_id', 'dow', 'visitors_mv']],\n",
    "                                                           on=('air_store_id', 'dow'), how='left')['visitors_mv_y'].values\n",
    "miss_idx = test['visitors_mv'].isnull()\n",
    "test.loc[miss_idx, 'visitors_mv'] = test[miss_idx].merge(visitors_mv[['air_store_id', 'visitors_mv']].groupby('air_store_id').mean().reset_index(),\n",
    "                                                           on='air_store_id', how='left')['visitors_mv_y'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准化 & 变量转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>doy</th>\n",
       "      <th>date_int</th>\n",
       "      <th>...</th>\n",
       "      <th>max_ga_d</th>\n",
       "      <th>std_ga_d</th>\n",
       "      <th>len_ga_d</th>\n",
       "      <th>penet_ga</th>\n",
       "      <th>store_num</th>\n",
       "      <th>area_store_num</th>\n",
       "      <th>genre_store_num</th>\n",
       "      <th>area_store_ratio</th>\n",
       "      <th>genre_store_ratio</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20160113</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>11.643092</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>2.915902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20160114</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11.576332</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>2.739233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>20160115</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.187465</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>3.519119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20160116</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.351608</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>3.184821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>20160118</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.264949</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>2.200934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors  year  dow  month  season  week  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13        25  2016    2      1       1     2   \n",
       "1  air_ba937bf13d40fb24 2016-01-14        32  2016    3      1       1     2   \n",
       "2  air_ba937bf13d40fb24 2016-01-15        29  2016    4      1       1     2   \n",
       "3  air_ba937bf13d40fb24 2016-01-16        22  2016    5      1       1     2   \n",
       "4  air_ba937bf13d40fb24 2016-01-18         6  2016    0      1       1     3   \n",
       "\n",
       "   doy  date_int     ...       max_ga_d   std_ga_d  len_ga_d  penet_ga  \\\n",
       "0   13  20160113     ...           73.0  11.643092     399.0  0.009538   \n",
       "1   14  20160114     ...           79.0  11.576332     400.0  0.009538   \n",
       "2   15  20160115     ...           64.0  14.187465     404.0  0.009538   \n",
       "3   16  20160116     ...           67.0  12.351608     401.0  0.009538   \n",
       "4   18  20160118     ...           47.0   9.264949     322.0  0.009538   \n",
       "\n",
       "   store_num  area_store_num  genre_store_num  area_store_ratio  \\\n",
       "0        8.0            51.0            108.0          0.156863   \n",
       "1        8.0            51.0            108.0          0.156863   \n",
       "2        8.0            51.0            108.0          0.156863   \n",
       "3        8.0            51.0            108.0          0.156863   \n",
       "4        8.0            51.0            108.0          0.156863   \n",
       "\n",
       "   genre_store_ratio  visitors_mv  \n",
       "0           0.074074     2.915902  \n",
       "1           0.074074     2.739233  \n",
       "2           0.074074     3.519119  \n",
       "3           0.074074     3.184821  \n",
       "4           0.074074     2.200934  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Predict #0\n",
    "\n",
    "GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from sklearn.ensemble import GradientBoostingRegressor, \n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "\n",
    "rmsle_score = make_scorer(RMSLE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors', 'air_genre_name', 'air_area_name']]\n",
    "\n",
    "X, y = train[col], np.log1p(train['visitors'].values)\n",
    "\n",
    "# train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "# kfold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'n_estimators': [100, 300, 500, 800],\n",
    "    'max_depth': [3, 5, 8, 12],\n",
    "    'subsample': [0.8, ],\n",
    "    'max_features': ['sqrt',]\n",
    "    # 'min_samples_split': [200,],\n",
    "    # 'min_samples_leaf': [20,]\n",
    "    }\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "model0 = GridSearchCV(gbr, params, cv=kf , scoring=rmsle_score, verbose=3)\n",
    "model0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581f1ee5b01b4b62812758339e6be9a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors', 'air_genre_name', 'air_area_name']]\n",
    "\n",
    "X, y = train[col], np.log1p(train['visitors'].values)\n",
    "\n",
    "# train split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "# kfold\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'n_estimators': [100, 300, 500, 800],\n",
    "    'max_depth': [3, 5, 8, 12],\n",
    "    'subsample': [0.8, ],\n",
    "    'max_features': ['sqrt',]\n",
    "    # 'min_samples_split': [200,],\n",
    "    # 'min_samples_leaf': [20,]\n",
    "    }\n",
    "'''\n",
    "\n",
    "gbr = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    subsample=0.6,\n",
    "    max_features='sqrt',\n",
    "    random_state=0)\n",
    "\n",
    "num = 1\n",
    "scores = []\n",
    "for train_idx, test_idx in tqdm_notebook(kf.split(X)):\n",
    "    # print(\"Traing Fold#%d\" % num)\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    gbr.fit(X_train, y_train)\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    scores.append(RMSLE(y_test, y_pred))\n",
    "    # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45655590768729054"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8e3198>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkEKdxGRCFK4i4hEkMJdRCSC/j9CsO645VmW7QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f1e8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gbr.oob_improvement_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>visitors_mv</td>\n",
       "      <td>0.039150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ratio_s_w</td>\n",
       "      <td>0.035499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>date_int</td>\n",
       "      <td>0.029885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mean_s_d</td>\n",
       "      <td>0.024049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ratio_s_d</td>\n",
       "      <td>0.023212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>doy</td>\n",
       "      <td>0.022252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>median_s_d</td>\n",
       "      <td>0.021991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>max_s_w</td>\n",
       "      <td>0.021541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>median_visitors</td>\n",
       "      <td>0.020692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>median_s_w</td>\n",
       "      <td>0.018728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>min_s_m</td>\n",
       "      <td>0.018483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mean_visitors</td>\n",
       "      <td>0.018215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mean_s_w</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>min_s_w</td>\n",
       "      <td>0.016555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>std_s_d</td>\n",
       "      <td>0.016253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ratio_s_m</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>max_s_m</td>\n",
       "      <td>0.015968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>ratio_g_w</td>\n",
       "      <td>0.014863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ratio_a_w</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>median_s_m</td>\n",
       "      <td>0.011503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cols       imp\n",
       "154      visitors_mv  0.039150\n",
       "68         ratio_s_w  0.035499\n",
       "6           date_int  0.029885\n",
       "70          mean_s_d  0.024049\n",
       "75         ratio_s_d  0.023212\n",
       "5                doy  0.022252\n",
       "71        median_s_d  0.021991\n",
       "67           max_s_w  0.021541\n",
       "17   median_visitors  0.020692\n",
       "66        median_s_w  0.018728\n",
       "57           min_s_m  0.018483\n",
       "16     mean_visitors  0.018215\n",
       "65          mean_s_w  0.016933\n",
       "64           min_s_w  0.016555\n",
       "73           std_s_d  0.016253\n",
       "61         ratio_s_m  0.016234\n",
       "60           max_s_m  0.015968\n",
       "93         ratio_g_w  0.014863\n",
       "118        ratio_a_w  0.014541\n",
       "59        median_s_m  0.011503"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_imp = pd.DataFrame({'cols': X_train.columns, 'imp': gbr.feature_importances_})\n",
    "feats_imp.sort_values(by='imp', ascending=False, inplace=True)\n",
    "feats_imp.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Predict #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 辅助计时函数\n",
    "def time_cnt(delta):\n",
    "    total_secs = int(delta.total_seconds())\n",
    "    format = '{h}H: {m}M: {s}S'\n",
    "    h, m = total_secs // 3600, total_secs % 3600\n",
    "    m, s = m // 60, m % 60\n",
    "    return format.format(h=h, m=m, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling...\n",
      "Training...\n",
      "Time consume:  0H: 4M: 48S\n",
      "RMSE GradientBoostingRegressor:  0.456443449301\n",
      "RMSE KNeighborsRegressor:  0.489168172841\n",
      "Time consume:  0H: 4M: 43S\n"
     ]
    }
   ],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors', 'air_genre_name', 'air_area_name']]\n",
    "\n",
    "time0 = datetime.now()\n",
    "print(\"Modeling...\")\n",
    "model1 = GradientBoostingRegressor(learning_rate=0.2, random_state=3)\n",
    "model2 = KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "\n",
    "print(\"Training...\")\n",
    "# model1\n",
    "model1.fit(train[col], np.log1p(train['visitors'].values))\n",
    "visitors_pred1 = model1.predict(train[col])\n",
    "print(\"Time consume: \", time_cnt(datetime.now()-time0))\n",
    "\n",
    "# model2\n",
    "time0 = datetime.now()\n",
    "model2.fit(train[col], np.log1p(train['visitors'].values))\n",
    "visitors_pred2 = model2.predict(train[col])\n",
    "\n",
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), visitors_pred1))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(train['visitors'].values), visitors_pred2))\n",
    "print(\"Time consume: \", time_cnt(datetime.now()-time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Predict #2 Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.325868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.353439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.475056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  holiday_flg  visitors_mv\n",
       "0  air_00a91d42b08b08d9    0          0.0     3.203625\n",
       "1  air_00a91d42b08b08d9    0          1.0     3.091042\n",
       "2  air_00a91d42b08b08d9    1          0.0     3.325868\n",
       "3  air_00a91d42b08b08d9    2          0.0     3.353439\n",
       "4  air_00a91d42b08b08d9    3          0.0     3.475056"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_mv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_avg(tra, hol):\n",
    "    air_visit_data = tra.copy()\n",
    "    date_info = hol.copy()\n",
    "    # 把周末的holiday_flag置为0\n",
    "    date_info.loc[(date_info['visit_date'].dt.dayofweek>4) & date_info['holiday_flg']==1, :] = 0\n",
    "\n",
    "    # 根据hol.index计算日期对应的权重weight\n",
    "    date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5\n",
    "\n",
    "    # 在visit_data中匹配日期weight\n",
    "    visit_data = air_visit_data.merge(date_info, on='visit_date', how='left')\n",
    "\n",
    "    # 将访问量转化为对数访问量log1p\n",
    "    visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "    # 按照 air_store_id, dow, holiday_flg 的分组计算加权平均\n",
    "    visitors = visit_data.groupby(['air_store_id', 'dow', 'holiday_flg']).apply(\n",
    "        lambda x:( (x['weight'] * x['visitors']).sum() / x['weight'].sum() )).reset_index()\n",
    "    visitors.rename(columns={0:'visitors'}, inplace=True) \n",
    "    return visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  holiday_flg  visitors_mv\n",
       "0  air_00a91d42b08b08d9    0          0.0     3.203625\n",
       "1  air_00a91d42b08b08d9    0          1.0     3.091042"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_mv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>rs1_x</th>\n",
       "      <th>rv1_x</th>\n",
       "      <th>...</th>\n",
       "      <th>air_area_name5</th>\n",
       "      <th>air_area_name6</th>\n",
       "      <th>var_max_lat</th>\n",
       "      <th>var_max_long</th>\n",
       "      <th>lon_plus_lat</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>total_reserv_sum</th>\n",
       "      <th>total_reserv_mean</th>\n",
       "      <th>total_reserv_dt_diff_mean</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.325868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.353439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.475056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors visit_date          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0 2017-04-23  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24         0 2017-04-24  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25         0 2017-04-25  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26         0 2017-04-26  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27         0 2017-04-27  air_00a91d42b08b08d9   \n",
       "\n",
       "   dow  month  season  week  rs1_x  rv1_x     ...       air_area_name5  \\\n",
       "0    6      4       2    16    0.0    0.0     ...                    0   \n",
       "1    0      4       2    17    0.0    0.0     ...                    0   \n",
       "2    1      4       2    17    0.0    0.0     ...                    0   \n",
       "3    2      4       2    17    0.0    0.0     ...                    0   \n",
       "4    3      4       2    17    0.0    0.0     ...                    0   \n",
       "\n",
       "   air_area_name6  var_max_lat  var_max_long  lon_plus_lat  holiday_flg  \\\n",
       "0               0     8.326629      4.519803    175.447598          0.0   \n",
       "1               0     8.326629      4.519803    175.447598          0.0   \n",
       "2               0     8.326629      4.519803    175.447598          0.0   \n",
       "3               0     8.326629      4.519803    175.447598          0.0   \n",
       "4               0     8.326629      4.519803    175.447598          0.0   \n",
       "\n",
       "   total_reserv_sum  total_reserv_mean  total_reserv_dt_diff_mean  visitors_mv  \n",
       "0               0.0                0.0                        0.0     1.098612  \n",
       "1               0.0                0.0                        0.0     3.203625  \n",
       "2               0.0                0.0                        0.0     3.325868  \n",
       "3               0.0                0.0                        0.0     3.353439  \n",
       "4               0.0                0.0                        0.0     3.475056  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = test[['id','visitors']].copy()\n",
    "sub1['visitors'] = (model1.predict(test[col]) + model2.predict(test[col])) / 2\n",
    "sub1['visitors'] = np.expm1(sub1['visitors']).clip(lower=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub2 = test[['id', 'visitors_mv']].copy()\n",
    "sub2['visitors'] = sub2['visitors_mv'].map(pd.np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors_mv</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>3.203625</td>\n",
       "      <td>23.621632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>3.325868</td>\n",
       "      <td>26.823130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>3.353439</td>\n",
       "      <td>27.600920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>3.475056</td>\n",
       "      <td>31.299646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors_mv   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23     1.098612   2.000000\n",
       "1  air_00a91d42b08b08d9_2017-04-24     3.203625  23.621632\n",
       "2  air_00a91d42b08b08d9_2017-04-25     3.325868  26.823130\n",
       "3  air_00a91d42b08b08d9_2017-04-26     3.353439  27.600920\n",
       "4  air_00a91d42b08b08d9_2017-04-27     3.475056  31.299646"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')\n",
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission%s.csv' % datetime.now().strftime('%M%S'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
