{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证策略\n",
    "\n",
    "[Scikit-learn validator](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "\n",
    "[Cross-validation for time series](https://robjhyndman.com/hyndsight/tscv/)\n",
    "\n",
    "[Ordered cross-validation](https://github.com/MaxHalford/xam/blob/master/docs/model-selection.md#ordered-cross-validation)\n",
    "\n",
    "[Cross-Validation Methodology Using '16 Golden Week](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/45266)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('./data/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('./data/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('./data/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('./data/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('./data/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('./data/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('./data/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('./data/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "# 初始处理:\n",
    "#       1. 从tes数据id中提取air_store_id和visit_datetime\n",
    "#       2. 在HPG预订信息中匹配air_store_id\n",
    "#       2. 转换visit_datetime和reserve_datetime为时间格式\n",
    "print(\"Init.\")\n",
    "# 1.\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "# 2.\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "# 3.\n",
    "for k in data:\n",
    "    if 'visit_date' in data[k].columns:\n",
    "        data[k]['visit_date'] = pd.to_datetime(data[k]['visit_date'])\n",
    "    if 'visit_datetime' in data[k].columns:\n",
    "        data[k]['visit_date'] = pd.to_datetime(data[k]['visit_datetime'].str.split().str[0])\n",
    "        data[k].drop('visit_datetime', axis=1, inplace=True)\n",
    "    if 'reserve_datetime' in data[k].columns:\n",
    "        data[k]['reserve_date'] = pd.to_datetime(data[k]['reserve_datetime'].str.split().str[0])\n",
    "        data[k].drop('reserve_datetime', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义特征抽取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为df加上时间标记: dow, month, year, date\n",
    "def time_feats(df, dt_col='visit_date'):\n",
    "    df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    df.loc[:, 'dow'] = df[dt_col].dt.dayofweek\n",
    "    df.loc[:, 'month'] = df[dt_col].dt.month\n",
    "    df.loc[:, 'season'] = df[dt_col].dt.quarter\n",
    "    df.loc[:, 'week'] = df[dt_col].dt.weekofyear\n",
    "    df.loc[:, 'date_int'] = df[dt_col].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "    return df\n",
    "\n",
    "# 预订数据特征\n",
    "# WARNING: 测试数据中没有reserve数据, 只有reserve_visit数据 \n",
    "def order_feats(order_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `visit_date`, ...\n",
    "    '''\n",
    "    order = order_data.copy()\n",
    "    # 创建新特征datetime_diff: 表示到店时间和预订时间的差值\n",
    "    order['reserve_date_diff'] = order.apply(\n",
    "        lambda r: (r['visit_date'] - r['reserve_date']).days,\n",
    "        axis=1)\n",
    "\n",
    "    # 以(air_store_id, visit_date)为分组计算预订时间差和预订人数的总和(sum: tmp1)与均值(mean: tmp2)\n",
    "    tmp1 = order.groupby(['air_store_id','visit_date'],\n",
    "        as_index=False)[['reserve_date_diff', 'reserve_visitors']].sum().rename(\n",
    "        columns={'visit_date':'visit_date', 'reserve_date_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = order.groupby(['air_store_id','visit_date'],\n",
    "        as_index=False)[['reserve_date_diff', 'reserve_visitors']].mean().rename(\n",
    "        columns={'visit_date':'visit_date', 'reserve_date_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    order = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "    return order\n",
    "\n",
    "\n",
    "# 以(air_store_id, dow)为分组，计算visitors的最小值，均值，中位数，最大值，样本大小\n",
    "# 主要计算了时间（dow）相关的信息\n",
    "def store_x_dow(tra, tes):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `dow`, ...\n",
    "    '''\n",
    "    unique_stores = tes['air_store_id'].unique()\n",
    "    stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores,\n",
    "                                      'dow': [i]*len(unique_stores)}) for i in range(7)],\n",
    "                        axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    tmp = tra.groupby(['air_store_id','dow']).agg(\n",
    "        {'visitors': [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n",
    "    tmp.columns = ['air_store_id', 'dow', 'min_visitors', 'mean_visitors',\n",
    "                   'median_visitors','max_visitors','count_observations']\n",
    "    stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "    return stores\n",
    "\n",
    "\n",
    "def genre_feats(store_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, ...\n",
    "    '''\n",
    "    store_info = store_data[['air_store_id', 'air_genre_name']].copy()\n",
    "    store_info['air_genre_name'] = store_info['air_genre_name'].map(\n",
    "        lambda x: str(str(x).replace('/',' ')))\n",
    "\n",
    "    lbl = LabelEncoder()\n",
    "    max_genre = np.max((store_info['air_genre_name'].str.split().apply(lambda x: len(x))))\n",
    "    for i in range(max_genre):\n",
    "        store_info['air_genre_name'+str(i)] = lbl.fit_transform(store_info['air_genre_name'].map(\n",
    "            lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    store_info['air_genre_name'] = lbl.fit_transform(store_info['air_genre_name'])\n",
    "    return store_info\n",
    "\n",
    "\n",
    "def area_feats(store_data):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, ...\n",
    "    '''\n",
    "    store_info = store_data[['air_store_id', 'air_area_name', 'latitude', 'longitude']].copy()\n",
    "    # 区域名称特征\n",
    "    store_info['air_area_name'] = store_info['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "\n",
    "    lbl = LabelEncoder()\n",
    "    max_area = np.max((store_info['air_area_name'].str.split().apply(lambda x: len(x))))\n",
    "    for i in range(max_area):\n",
    "        store_info['air_area_name'+str(i)] = lbl.fit_transform(store_info['air_area_name'].map(\n",
    "            lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    store_info['air_area_name'] = lbl.fit_transform(store_info['air_area_name'])\n",
    "\n",
    "    # 区域坐标特征\n",
    "    # 经纬度特征\n",
    "    store_info['var_max_lat'] = store_info['latitude'].max() - store_info['latitude']\n",
    "    store_info['var_max_long'] = store_info['longitude'].max() - store_info['longitude']\n",
    "    # NEW FEATURES FROM Georgii Vyshnia\n",
    "    # 经度 + 纬度?\n",
    "    store_info['lon_plus_lat'] = store_info['longitude'] + store_info['latitude']\n",
    "\n",
    "    return store_info\n",
    "\n",
    "\n",
    "def holiday_feats(holiday):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `visit_date`, ...\n",
    "    '''\n",
    "    tmp = holiday.drop('day_of_week', axis=1)\n",
    "    # 周末的holiday_flg置为0\n",
    "    tmp.loc[(tmp['visit_date'].dt.dayofweek>4) & tmp['holiday_flg']==1, :] = 0\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def mean_avg(tra, hol):\n",
    "    '''\n",
    "    Return:\n",
    "    -----\n",
    "    `air_store_id`, `dow`, `holiday_flg`, `visitors_mv`\n",
    "    '''\n",
    "    air_visit_data = tra.copy()\n",
    "    date_info = hol.copy()\n",
    "    # 把周末的holiday_flag置为0\n",
    "    date_info.loc[(date_info['visit_date'].dt.dayofweek>4) & date_info['holiday_flg']==1, :] = 0\n",
    "\n",
    "    # 根据hol.index计算日期对应的权重weight\n",
    "    date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5\n",
    "\n",
    "    # 在visit_data中匹配日期weight\n",
    "    visit_data = air_visit_data.merge(date_info, on='visit_date', how='left')\n",
    "\n",
    "    # 将访问量转化为对数访问量log1p\n",
    "    visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "    # 按照 air_store_id, dow, holiday_flg 的分组计算加权平均\n",
    "    visitors = visit_data.groupby(['air_store_id', 'dow', 'holiday_flg']).apply(\n",
    "        lambda x:( (x['weight'] * x['visitors']).sum() / x['weight'].sum() )).reset_index()\n",
    "    visitors.rename(columns={0:'visitors_mv'}, inplace=True) \n",
    "    return visitors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set features.\n",
      "Processing Order data...\n",
      "Processing Store X dow...\n",
      "Processing Genre_feats...\n",
      "Processing Area_feats...\n",
      "Processing Holiday_feats...\n",
      "Test set features.\n",
      "Processing Order data...\n",
      "Processing Store X dow...\n",
      "Processing Genre_feats...\n",
      "Processing Area_feats...\n",
      "Processing Holiday_feats...\n",
      "Processing Total_order_feats...\n",
      "Processing lat&lon_feats...\n"
     ]
    }
   ],
   "source": [
    "train = time_feats(data['tra'])\n",
    "test = time_feats(data['tes'])\n",
    "\n",
    "'''\n",
    "for df in [train, test]:\n",
    "    print(\"Processing Order data...\")\n",
    "    df = pd.merge(df, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "    df = pd.merge(df, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "    print(\"Processing Store X dow...\")\n",
    "    df = pd.merge(df, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "    print(\"Processing Genre_feats...\")\n",
    "    df = pd.merge(df, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "    print(\"Processing Area_feats...\")\n",
    "    df = pd.merge(df, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "    print(\"Processing Holiday_feats...\")\n",
    "    df = pd.merge(df, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "    df.fillna(-1)\n",
    "'''\n",
    "\n",
    "print(\"Train set features.\")\n",
    "print(\"Processing Order data...\")\n",
    "train = pd.merge(train, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "train = pd.merge(train, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "print(\"Processing Store X dow...\")\n",
    "train = pd.merge(train, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "print(\"Processing Genre_feats...\")\n",
    "train = pd.merge(train, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Area_feats...\")\n",
    "train = pd.merge(train, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Holiday_feats...\")\n",
    "train = pd.merge(train, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "train.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Test set features.\")\n",
    "print(\"Processing Order data...\")\n",
    "test = pd.merge(test, order_feats(data['ar']), how='left', on=['air_store_id', 'visit_date'])\n",
    "test = pd.merge(test, order_feats(data['hr']), how='left', on=['air_store_id', 'visit_date'])\n",
    "print(\"Processing Store X dow...\")\n",
    "test = pd.merge(test, store_x_dow(data['tra'], data['tes']), how='left', on=['air_store_id', 'dow'])\n",
    "print(\"Processing Genre_feats...\")\n",
    "test = pd.merge(test, genre_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Area_feats...\")\n",
    "test = pd.merge(test, area_feats(data['as']), how='left', on=['air_store_id'])\n",
    "print(\"Processing Holiday_feats...\")\n",
    "test = pd.merge(test, holiday_feats(data['hol']), how='left', on=['visit_date'])\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "# 增加预订总和以及预订平均值特征\n",
    "print(\"Processing Total_order_feats...\")\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "# 经纬度特征\n",
    "print(\"Processing lat&lon_feats...\")\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "# 经度 + 纬度?\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude']\n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移动平均预测特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mean Average feats...\n",
      "\tProcessing Train set\n",
      "\tProcessing Test set\n"
     ]
    }
   ],
   "source": [
    "# 添加移动平均预测特征\n",
    "print(\"Processing Mean Average feats...\")\n",
    "visitors_mv = mean_avg(data['tra'], data['hol'])\n",
    "\n",
    "print(\"\\tProcessing Train set\")\n",
    "train = pd.merge(train, visitors_mv, how='left', on=['air_store_id', 'dow', 'holiday_flg'])\n",
    "miss_idx = train['visitors_mv'].isnull()\n",
    "train.loc[miss_idx, 'visitors_mv'] = train[miss_idx].merge(visitors_mv.loc[visitors_mv.holiday_flg==0, ['air_store_id', 'dow', 'visitors_mv']],\n",
    "                                                           on=('air_store_id', 'dow'), how='left')['visitors_mv_y'].values\n",
    "miss_idx = train['visitors_mv'].isnull()\n",
    "train.loc[miss_idx, 'visitors_mv'] = train[miss_idx].merge(visitors_mv[['air_store_id', 'visitors_mv']].groupby('air_store_id').mean().reset_index(),\n",
    "                                                           on='air_store_id', how='left')['visitors_mv_y'].values\n",
    "\n",
    "print(\"\\tProcessing Test set\")\n",
    "test = pd.merge(test, visitors_mv, how='left', on=['air_store_id', 'dow', 'holiday_flg'])\n",
    "miss_idx = test['visitors_mv'].isnull()\n",
    "test.loc[miss_idx, 'visitors_mv'] = test[miss_idx].merge(visitors_mv.loc[visitors_mv.holiday_flg==0, ['air_store_id', 'dow', 'visitors_mv']],\n",
    "                                                           on=('air_store_id', 'dow'), how='left')['visitors_mv_y'].values\n",
    "miss_idx = test['visitors_mv'].isnull()\n",
    "test.loc[miss_idx, 'visitors_mv'] = test[miss_idx].merge(visitors_mv[['air_store_id', 'visitors_mv']].groupby('air_store_id').mean().reset_index(),\n",
    "                                                           on='air_store_id', how='left')['visitors_mv_y'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准化 & 变量转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_store_id                         object\n",
       "visit_date                   datetime64[ns]\n",
       "visitors                              int64\n",
       "dow                                   int64\n",
       "month                                 int64\n",
       "season                                int64\n",
       "week                                  int64\n",
       "rs1_x                               float64\n",
       "rv1_x                               float64\n",
       "rs2_x                               float64\n",
       "rv2_x                               float64\n",
       "rs1_y                               float64\n",
       "rv1_y                               float64\n",
       "rs2_y                               float64\n",
       "rv2_y                               float64\n",
       "min_visitors                        float64\n",
       "mean_visitors                       float64\n",
       "median_visitors                     float64\n",
       "max_visitors                        float64\n",
       "count_observations                  float64\n",
       "air_genre_name                        int64\n",
       "air_genre_name0                       int64\n",
       "air_genre_name1                       int64\n",
       "air_genre_name2                       int64\n",
       "air_area_name                         int64\n",
       "latitude                            float64\n",
       "longitude                           float64\n",
       "air_area_name0                        int64\n",
       "air_area_name1                        int64\n",
       "air_area_name2                        int64\n",
       "air_area_name3                        int64\n",
       "air_area_name4                        int64\n",
       "air_area_name5                        int64\n",
       "air_area_name6                        int64\n",
       "var_max_lat                         float64\n",
       "var_max_long                        float64\n",
       "lon_plus_lat                        float64\n",
       "holiday_flg                         float64\n",
       "total_reserv_sum                    float64\n",
       "total_reserv_mean                   float64\n",
       "total_reserv_dt_diff_mean           float64\n",
       "visitors_mv                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_store_id', 'visit_date', 'visitors', 'dow', 'month', 'season',\n",
       "       'week', 'rs1_x', 'rv1_x', 'rs2_x', 'rv2_x', 'rs1_y', 'rv1_y', 'rs2_y',\n",
       "       'rv2_y', 'min_visitors', 'mean_visitors', 'median_visitors',\n",
       "       'max_visitors', 'count_observations', 'air_genre_name',\n",
       "       'air_genre_name0', 'air_genre_name1', 'air_genre_name2',\n",
       "       'air_area_name', 'latitude', 'longitude', 'air_area_name0',\n",
       "       'air_area_name1', 'air_area_name2', 'air_area_name3', 'air_area_name4',\n",
       "       'air_area_name5', 'air_area_name6', 'var_max_lat', 'var_max_long',\n",
       "       'lon_plus_lat', 'holiday_flg', 'total_reserv_sum', 'total_reserv_mean',\n",
       "       'total_reserv_dt_diff_mean', 'visitors_mv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Predict #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 辅助计时函数\n",
    "def time_cnt(delta):\n",
    "    total_secs = int(delta.total_seconds())\n",
    "    format = '{h}H: {m}M: {s}S'\n",
    "    h, m = total_secs // 3600, total_secs % 3600\n",
    "    m, s = m // 60, m % 60\n",
    "    return format.format(h=h, m=m, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling...\n",
      "Training...\n",
      "RMSE GradientBoostingRegressor:  0.497911892637\n",
      "RMSE KNeighborsRegressor:  0.422111222092\n",
      "0H: 6M: 16S\n"
     ]
    }
   ],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "time0 = datetime.now()\n",
    "print(\"Modeling...\")\n",
    "model1 = GradientBoostingRegressor(learning_rate=0.2, random_state=3)\n",
    "model2 = KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "\n",
    "print(\"Training...\")\n",
    "model1.fit(train[col], np.log1p(train['visitors'].values))\n",
    "model2.fit(train[col], np.log1p(train['visitors'].values))\n",
    "\n",
    "visitors_pred1 = model1.predict(train[col])\n",
    "visitors_pred2 = model2.predict(train[col])\n",
    "\n",
    "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), visitors_pred1))\n",
    "print('RMSE KNeighborsRegressor: ', RMSLE(np.log1p(train['visitors'].values), visitors_pred2))\n",
    "print(time_cnt(datetime.now()-time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Predict #2 Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.325868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.353439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.475056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  holiday_flg  visitors_mv\n",
       "0  air_00a91d42b08b08d9    0          0.0     3.203625\n",
       "1  air_00a91d42b08b08d9    0          1.0     3.091042\n",
       "2  air_00a91d42b08b08d9    1          0.0     3.325868\n",
       "3  air_00a91d42b08b08d9    2          0.0     3.353439\n",
       "4  air_00a91d42b08b08d9    3          0.0     3.475056"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_mv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_avg(tra, hol):\n",
    "    air_visit_data = tra.copy()\n",
    "    date_info = hol.copy()\n",
    "    # 把周末的holiday_flag置为0\n",
    "    date_info.loc[(date_info['visit_date'].dt.dayofweek>4) & date_info['holiday_flg']==1, :] = 0\n",
    "\n",
    "    # 根据hol.index计算日期对应的权重weight\n",
    "    date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5\n",
    "\n",
    "    # 在visit_data中匹配日期weight\n",
    "    visit_data = air_visit_data.merge(date_info, on='visit_date', how='left')\n",
    "\n",
    "    # 将访问量转化为对数访问量log1p\n",
    "    visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "    # 按照 air_store_id, dow, holiday_flg 的分组计算加权平均\n",
    "    visitors = visit_data.groupby(['air_store_id', 'dow', 'holiday_flg']).apply(\n",
    "        lambda x:( (x['weight'] * x['visitors']).sum() / x['weight'].sum() )).reset_index()\n",
    "    visitors.rename(columns={0:'visitors'}, inplace=True) \n",
    "    return visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  holiday_flg  visitors_mv\n",
       "0  air_00a91d42b08b08d9    0          0.0     3.203625\n",
       "1  air_00a91d42b08b08d9    0          1.0     3.091042"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_mv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>rs1_x</th>\n",
       "      <th>rv1_x</th>\n",
       "      <th>...</th>\n",
       "      <th>air_area_name5</th>\n",
       "      <th>air_area_name6</th>\n",
       "      <th>var_max_lat</th>\n",
       "      <th>var_max_long</th>\n",
       "      <th>lon_plus_lat</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>total_reserv_sum</th>\n",
       "      <th>total_reserv_mean</th>\n",
       "      <th>total_reserv_dt_diff_mean</th>\n",
       "      <th>visitors_mv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.203625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.325868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.353439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.326629</td>\n",
       "      <td>4.519803</td>\n",
       "      <td>175.447598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.475056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors visit_date          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0 2017-04-23  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24         0 2017-04-24  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25         0 2017-04-25  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26         0 2017-04-26  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27         0 2017-04-27  air_00a91d42b08b08d9   \n",
       "\n",
       "   dow  month  season  week  rs1_x  rv1_x     ...       air_area_name5  \\\n",
       "0    6      4       2    16    0.0    0.0     ...                    0   \n",
       "1    0      4       2    17    0.0    0.0     ...                    0   \n",
       "2    1      4       2    17    0.0    0.0     ...                    0   \n",
       "3    2      4       2    17    0.0    0.0     ...                    0   \n",
       "4    3      4       2    17    0.0    0.0     ...                    0   \n",
       "\n",
       "   air_area_name6  var_max_lat  var_max_long  lon_plus_lat  holiday_flg  \\\n",
       "0               0     8.326629      4.519803    175.447598          0.0   \n",
       "1               0     8.326629      4.519803    175.447598          0.0   \n",
       "2               0     8.326629      4.519803    175.447598          0.0   \n",
       "3               0     8.326629      4.519803    175.447598          0.0   \n",
       "4               0     8.326629      4.519803    175.447598          0.0   \n",
       "\n",
       "   total_reserv_sum  total_reserv_mean  total_reserv_dt_diff_mean  visitors_mv  \n",
       "0               0.0                0.0                        0.0     1.098612  \n",
       "1               0.0                0.0                        0.0     3.203625  \n",
       "2               0.0                0.0                        0.0     3.325868  \n",
       "3               0.0                0.0                        0.0     3.353439  \n",
       "4               0.0                0.0                        0.0     3.475056  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = test[['id','visitors']].copy()\n",
    "sub1['visitors'] = (model1.predict(test[col]) + model2.predict(test[col])) / 2\n",
    "sub1['visitors'] = np.expm1(sub1['visitors']).clip(lower=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub2 = test[['id', 'visitors_mv']].copy()\n",
    "sub2['visitors'] = sub2['visitors_mv'].map(pd.np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors_mv</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>3.203625</td>\n",
       "      <td>23.621632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>3.325868</td>\n",
       "      <td>26.823130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>3.353439</td>\n",
       "      <td>27.600920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>3.475056</td>\n",
       "      <td>31.299646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors_mv   visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23     1.098612   2.000000\n",
       "1  air_00a91d42b08b08d9_2017-04-24     3.203625  23.621632\n",
       "2  air_00a91d42b08b08d9_2017-04-25     3.325868  26.823130\n",
       "3  air_00a91d42b08b08d9_2017-04-26     3.353439  27.600920\n",
       "4  air_00a91d42b08b08d9_2017-04-27     3.475056  31.299646"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')\n",
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission%s.csv' % datetime.now().strftime('%M%S'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
